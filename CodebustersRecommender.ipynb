{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebuster STAT 535 Statistical Computing Project\n",
    "## Movie recommendation recommendation pipeline\n",
    "\n",
    "#### Goal\n",
    "Build a small real world deployment pipeline like it can be used in netflix / amazon\n",
    "\n",
    "## Approach\n",
    "\n",
    "Deploy three different classifiers / recommenders, based on quality of user profile:\n",
    "\n",
    "1) Case 0 rated movies: Supervised prediction with just user age, gender, and year of the movie\n",
    "\n",
    " - In case of cold-start: No user information available\n",
    "\n",
    "2) Case < 20 rated movies: Content-based recommender system\n",
    "\n",
    " - Content-based recommendation information about users and their taste. As we can see in the preprocessing, most of the users only rated one to five movies, implying that we have incomplete user-profiles. I think content-based recommendation makes sense here, because we can recommend similar movies, but not other categories that a user might like because we can not identify similar users with an incomplete user profile.\n",
    "\n",
    "3) Case >=20 rated movies:  Collaborative recommender system\n",
    "\n",
    " - Collaborative filtering makes sense if you have a good user profile, which we assume we have if a user rated more or equal than 10 movies. With a good user profile we can identify similar users and make more sophisticated recommendations, e.g. movies from other genres.\n",
    "\n",
    "#### Dataset\n",
    "We use the movie recommendation lab dataset, which is a subset of the MovieLens dataset (https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature\n",
    "\n",
    "- https://users.ece.cmu.edu/~dbatra/publications/assets/goel_batra_netflix.pdf\n",
    "- http://delivery.acm.org/10.1145/1460000/1454012/p11-park.pdf?ip=72.19.68.210&id=1454012&acc=ACTIVE%20SERVICE&key=73B3886B1AEFC4BB%2EB478147E31829731%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1543416754_7f92e0642e26e7ea732886879096c704\n",
    "- https://www.kaggle.com/prajitdatta/movielens-100k-dataset/kernels\n",
    "- https://medium.com/@james_aka_yale/the-4-recommendation-engines-that-can-predict-your-movie-tastes-bbec857b8223\n",
    "- https://www.kaggle.com/c/predict-movie-ratings\n",
    "- https://cseweb.ucsd.edu/classes/wi17/cse258-a/reports/a048.pdf\n",
    "- https://github.com/neilsummers/predict_movie_ratings/blob/master/movieratings.py\n",
    "- https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "### A few more\n",
    "- https://sci2s.ugr.es/keel/pdf/specific/congreso/xia_dong_06.pdf (Uses SMV for classification, then MF for recommendation)\n",
    "- https://www.kaggle.com/rounakbanik/movie-recommender-systems (Employs at least three Modules for recommendation)\n",
    "- http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.703.4954&rep=rep1&type=pdf (Close to what we need, but a little too involving)\n",
    "- https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0165868 (Uses SVM and correlation matrices...I have already tried the correlation approach, looks quite good, but how to quantify accuracy?)\n",
    "- https://www.quora.com/How-do-we-use-SVMs-in-a-collaborative-recommendation (A good thread on SVM)\n",
    "-http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/ (A good tutorial on matrix factorizasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (31620, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>movieID</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1193</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>1975</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  age gender  movieID                              name  year genre1  \\\n",
       "0     747    1      F     1193  One Flew Over the Cuckoo's Nest   1975  Drama   \n",
       "\n",
       "  genre2 genre3  rating  \n",
       "0    NaN    NaN       5  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all data\n",
    "df = pd.read_csv(\"allData.tsv\", sep='\\t')\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (31620, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID        name  year     genre1      genre2  genre3\n",
       "0        1  Toy Story   1995  Animation  Children's  Comedy"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie data\n",
    "movies = pd.read_csv(\"movies.tsv\", sep='\\t')\n",
    "print(f\"Shape: {df.shape}\")\n",
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>747</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating\n",
       "0     747     1193       5"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = pd.read_csv('ratings.csv')\n",
    "df_ratings.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform numerical rating to binary\n",
    "- 1, if user rates movie 4 or 5\n",
    "- 0, if user rates movie less than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].mask(df['rating'] < 4, 0, inplace=True)\n",
    "df['rating'].mask(df['rating'] > 3, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Classifier without specific user-information\n",
    "Scott's part with additions from Tobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "                            name\n",
      "movieID                         \n",
      "2078           Jungle Book, The \n",
      "3035             Mister Roberts \n",
      "2506          Other Sister, The \n",
      "3159              Fantasia 2000 \n",
      "3420     ...And Justice for All \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def recommendation_without_user_info(df, age, gender, number_recommendations):\n",
    "    '''\n",
    "    function returns 5 random movies which have been recommended by a gradient boosting classifier\n",
    "    without user information\n",
    "    \n",
    "    @param df: movie dataset 'allData'\n",
    "    @param age: user age\n",
    "    @param gender: user gender\n",
    "    @param number_recommendations: number of recommendations returned\n",
    "    '''\n",
    "    # fit\n",
    "    # ---------------------------------------------------\n",
    "    # User information before any movie ratings\n",
    "    X = df[['age', 'gender', 'year', 'genre1', 'genre2', 'genre3']]\n",
    "    y = df['rating'].as_matrix()\n",
    "\n",
    "    # Preprocessing\n",
    "    # One hot encoding\n",
    "    dummyvars = pd.get_dummies(X[['gender', 'genre1', 'genre2', 'genre3']])\n",
    "    # append the dummy variables to df\n",
    "    X = pd.concat([X[['age', 'year']], dummyvars], axis = 1).as_matrix()\n",
    "\n",
    "    print(\"GradientBoostingClassifier\")\n",
    "    gbclf = GradientBoostingClassifier(n_estimators=100)\n",
    "    gbclf.fit(X=X, y=y)\n",
    "    \n",
    "    # predict\n",
    "    # ---------------------------------------------------\n",
    "    # concat user age and gender with movie information, and make predictions\n",
    "    # e.g. user age 25 and male\n",
    "    X = df[['age', 'gender', 'year', 'genre1', 'genre2', 'genre3']]\n",
    "    # set age\n",
    "    X['age'] = age\n",
    "    dummyvars = pd.get_dummies(X[['gender', 'genre1', 'genre2', 'genre3']])\n",
    "    # set gender\n",
    "    dummyvars['gender_F'] = 0\n",
    "    dummyvars['gender_M'] = 0\n",
    "    if gender=='M':\n",
    "        dummyvars['gender_M'] = 1\n",
    "    elif gender=='F':\n",
    "        dummyvars['gender_F'] = 1\n",
    "    # append the dummy variables to df\n",
    "    X = pd.concat([X[['age', 'year']], dummyvars], axis = 1).as_matrix()\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = gbclf.predict(X=X)\n",
    "    \n",
    "    # concat predictions to movie information\n",
    "    df_pred = pd.concat([df[['movieID', 'name']], pd.DataFrame(y_pred, index=df.index, columns=['pred_rating'])], axis = 1)\n",
    "    # shuffle 5 random movies with rating 1\n",
    "    df_pred = df_pred[df_pred.pred_rating==1]\n",
    "    recommendation = df_pred.drop('pred_rating', axis=1).sample(number_recommendations, random_state=10).set_index('movieID')\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# test function\n",
    "print(recommendation_without_user_info(df=df, age=25, gender='F', number_recommendations=5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Content-based recommender\n",
    "Tobias' part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203    Mystery Science Theater 3000: The Movie\n",
       "216              Visitors, The (Les Visiteurs)\n",
       "373                               Delicatessen\n",
       "430                         Back to the Future\n",
       "703                                   Repo Man\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out from user input a movie that he rated\n",
    "def get_user_movie(df, user_ID):\n",
    "    '''\n",
    "    gets user information\n",
    "    \n",
    "    @param df: movie dataset 'allData'\n",
    "    @param user_id: target user_ID\n",
    "    '''\n",
    "    # return data from random sampled row of user\n",
    "    df_liked = df[df.rating==1]\n",
    "    movie = df[df['userID']==747].sample(1).name\n",
    "    \n",
    "    # strip space at the end before return\n",
    "    return movie.item().rstrip()\n",
    "\n",
    "# Function that get movie recommendations based on the cosine similarity score of movie genres\n",
    "def content_based_recommendation(movies, name, number_recommendations):\n",
    "    '''\n",
    "    Recommends number of similar movie based on movie title and similarity to movies in movie database\n",
    "    \n",
    "    @param movies: pandas dataframe with movie dataset with columns (movieID, name, genres_concat)\n",
    "    @param name: movie title as string\n",
    "    @param number_recommendations: number of recommendations returned as integer\n",
    "    '''\n",
    "    # fit\n",
    "    # ---------------------------------------------------\n",
    "    # Preprocessing for tf-idf vectorization\n",
    "    # Strip space at the end of string\n",
    "    movies['name'] = movies['name'].str.rstrip()\n",
    "    # Concat genres into one string\n",
    "    movies['genres_concat'] = movies[['genre1', 'genre2', 'genre3']].astype(str).apply(' '.join, axis=1)\n",
    "    # Remove nans in string and strip spaces at the end\n",
    "    movies['genres_concat'] = movies['genres_concat'].str.replace('nan','').str.rstrip()\n",
    "\n",
    "    # Create tf_idf matrix sklearn TfidfVectorizer\n",
    "    tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "    tfidf_matrix = tf.fit_transform(movies['genres_concat'])\n",
    "    \n",
    "    # calculate similarity matrix with cosine distance of tf_idf values\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    # Build a 1-dimensional array with movie titles\n",
    "    indices = pd.Series(movies.index, index=movies['name'])\n",
    "    \n",
    "    # predict\n",
    "    # ---------------------------------------------------\n",
    "    # Ranks movies according to similarity to requested movie\n",
    "    idx = indices[name]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:(number_recommendations+1)]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return movies.name.iloc[movie_indices]\n",
    "\n",
    "# get a movie that a user liked from user_ID provided\n",
    "movie_name = get_user_movie(df=df, user_ID=747)\n",
    "# make recommendation based on previous liked movie\n",
    "content_based_recommendation(movies=movies, name=movie_name, number_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Collaborative recommender\n",
    "Sixtus' part\n",
    "\n",
    "##### There are two approaches\n",
    "\n",
    "##### 1. Memory based approach: \n",
    "This can be divided into two, (i) user-item filtering and (ii) item-item filtering.\n",
    "\n",
    "In this, we basically calculate the closest the user or item using the Cosine similarity or Pearson correlation coefficients\n",
    "\n",
    "The cosine similarity for two users is computed as:\n",
    "\n",
    "$sim(u, u^{'}) = cos(\\theta) = \\frac{r_u.r_{u^{'}}}{||r_u||||r_{u^{'}}} = \\sum_i \\frac{r_{ui}r_{u^{'}i}}{\\sqrt{\\sum_ir_{ui}^2}\\sqrt{\\sum_ir_{u^{'}i}^2}}$\n",
    "\n",
    "Here $u$ and $u^{'}$ represents two different users.\n",
    "\n",
    "We can predict user-u’s rating for movie-i by taking weighted sum of movie-i ratings from all other users (u′s) where weighting is similarity number between each user and user-u.\n",
    "\n",
    "We now predict a users rating as follows:\n",
    "\n",
    "#### $\\hat{r_{ui}} = \\frac{\\sum_{u^{'}} sim(u, u^{'})r_{u^{'}i}}{\\sum_{u^{'}} |sim(u, u^{'})|}$\n",
    "\n",
    "Drawback:  its performance decreases when we have sparse data which hinders scalability of this approach for most of the real-world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_similarity(m_ratings, kind='user', epsilon=1e-9):\n",
    "    '''\n",
    "    compute the similarity\n",
    "    '''\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = m_ratings.dot(m_ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = m_ratings.T.dot(m_ratings) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "def top_k_movies(similarity, movie_idx, k=6):\n",
    "    return [np.argsort(similarity[movie_idx,:])[:-k-1:-1]]\n",
    "\n",
    "def collaborative_recommendation(all_data, df_ratings, user_id, number_recommendations):\n",
    "    '''\n",
    "    Recommends number of similar movies based on user item similarity\n",
    "    \n",
    "    @param df_ratings: rating file from MovieLens dataset\n",
    "    @param userID: userID\n",
    "    @param number_recommendations: number of recommendations returned as integer\n",
    "    @param number_recommendations: number of recommendations returned\n",
    "    \n",
    "    '''\n",
    "    # fit\n",
    "    # ---------------------------------------------------\n",
    "    # Below code creates two new columns for user id and movie id to facilitate the creation of the user item matrix\n",
    "    from itertools import cycle\n",
    "    n_users = df_ratings.userID.unique().shape[0]\n",
    "    n_movies = df_ratings.movieID.unique().shape[0]\n",
    "\n",
    "    l_users = cycle(list(range(n_users)))\n",
    "    l_movies = list(range(n_movies))\n",
    "    df_ratings['user_id'] = df_ratings['userID'].astype(\"int\")\n",
    "    df_ratings['movie_id'] = df_ratings['movieID'].astype(\"int\")\n",
    "    df_ratings['movieID'] = df_ratings['movieID'].astype(\"int\")\n",
    "    #df_ratings['movie_id2'] = df_ratings['movie_id'].astype(\"str\")\n",
    "    current_idm = 1\n",
    "    current_idu = 747\n",
    "    indm = 1\n",
    "    indu = 1\n",
    "    listMID = list(df_ratings[\"movieID\"])\n",
    "    for idx, row in df_ratings.iterrows():\n",
    "        new_idm = int(df_ratings.loc[idx, 'movieID'])\n",
    "        #intialize the  foudn movie id in list\n",
    "        foundm = False\n",
    "        for k in range(1465):\n",
    "            if new_idm in listMID:\n",
    "                #get the index\n",
    "                lind = listMID.index(new_idm)\n",
    "                #update the movie_id\n",
    "                df_ratings.loc[lind, 'movie_id'] = indm\n",
    "                #now set that list item to zero\n",
    "                listMID[lind]=0\n",
    "                foundm = True\n",
    "            else:\n",
    "                #break and fetch a new row\n",
    "                break\n",
    "        #increment the indicator\n",
    "        if foundm:\n",
    "            indm+=1\n",
    "        #current_idm = new_idm\n",
    "\n",
    "        #there is a bit of logic problem here...\n",
    "        new_idu = int(df_ratings.loc[idx, 'userID'])\n",
    "        if new_idu==current_idu:\n",
    "            df_ratings.loc[idx, 'user_id'] = indu\n",
    "        else:\n",
    "            indu+=1\n",
    "            current_idu = new_idu\n",
    "            df_ratings.loc[idx, 'user_id'] = indu\n",
    "\n",
    "    ## construct a user item matrix\n",
    "    m_ratings = np.zeros((n_users, n_movies))\n",
    "    for row in df_ratings.itertuples():\n",
    "        #row[3] will be user rating row[4] user_id and row[5] movie_id  \n",
    "        m_ratings[row[4]-1, row[5]-1] = row[3]\n",
    "        \n",
    "    # get item similarity matrix\n",
    "    item_similarity = fast_similarity(m_ratings, kind='item')\n",
    "    \n",
    "    # predict\n",
    "    # ---------------------------------------------------\n",
    "    movies  = top_k_movies(item_similarity, user_id, number_recommendations)\n",
    "    return all_data.loc[movies[0]-1, 'name']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746     Elephant Man, The \n",
       "743    North by Northwest \n",
       "739    Lady and the Tramp \n",
       "744       West Side Story \n",
       "738    As Good As It Gets \n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make recommendation with collaborative recommender\n",
    "collaborative_recommendation(all_data=df, df_ratings=df_ratings, user_id=747, number_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Recommender: CodebustersRecommender\n",
    "Fits all three recommendation methods in fit method. When predicting, predict method assesses quality of user profile and predicts with respective method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Fill template with our logic \n",
    "\n",
    "class TemplateClassifier():\n",
    "    \"\"\" \n",
    "    Implements a three stage recommendation system with a gradient boosting classifier, \n",
    "    a content-based recommender, and collaborative filter\n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The target values. An array of int.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # 1) fit gradient boosting classifier\n",
    "        \n",
    "        \n",
    "        # 2) fit content-based recommender\n",
    "        \n",
    "        \n",
    "        # 3) fit collaborative recommender\n",
    "        \n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            The label for each sample is the label of the closest sample\n",
    "            seen udring fit.\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1) predict with gradient boosting classifier\n",
    "        \n",
    "        \n",
    "        # 2) predict with content-based recommender\n",
    "        \n",
    "        \n",
    "        # 3) predict with collaborative recommender\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.y_[closest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problems with evaluation\n",
    "- Evaluation with a metric for content-based and collaborative approach is hardly possible, because a lot of recommended movies haven't been rated by the initial user yet!\n",
    "    - 1) Simple Classifier without user info\n",
    "        - Precision / Recall evaluation\n",
    "    - 2) Content-based recommendation\n",
    "        - Precision / Recall hardly possible, instead just recommend movies\n",
    "    - 3) Collaborative recommendation\n",
    "        - Precision / Recall hardly possible, instead just recommend movies\n",
    "        \n",
    "##### Possible solutions\n",
    "- Way larger datasets which are not as sparse\n",
    "\n",
    "- Evaluate user's reaction after recommendation is given (e.g. in Netflix, if he likes the movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation to test and anticipate overfitting problem\n",
    "def crossvalidate(clf, X,y):\n",
    "    '''\n",
    "    Calculate precision, recall, and roc_auc for a 10-fold cross validation run with passed classifier\n",
    "    '''\n",
    "    scores1 = cross_val_score(clf, X, y, cv=10, scoring='precision')\n",
    "    scores2 = cross_val_score(clf, X, y, cv=10, scoring='recall')\n",
    "    scores3 = cross_val_score(clf, X, y, cv=10, scoring='roc_auc')\n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "# from http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "def get_crossval_roc(clfname, classifier,X,y):\n",
    "    '''\n",
    "    Run classifier with cross-validation and plot ROC curves\n",
    "    '''\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=6)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
