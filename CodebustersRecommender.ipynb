{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codebuster STAT 535 Statistical Computing Project\n",
    "## Movie recommendation recommendation pipeline\n",
    "\n",
    "#### Goal\n",
    "Build a small real world deployment pipeline like it can be used in netflix / amazon\n",
    "\n",
    "## Approach\n",
    "\n",
    "Deploy three different classifiers / recommenders, based on quality of user profile:\n",
    "\n",
    "1) Case 0 rated movies: Supervised prediction with just user age, gender, and year of the movie\n",
    "\n",
    " - In case of cold-start: No user information available\n",
    "\n",
    "2) Case < 20 rated movies: Content-based recommender system\n",
    "\n",
    " - Content-based recommendation information about users and their taste. As we can see in the preprocessing, most of the users only rated one to five movies, implying that we have incomplete user-profiles. I think content-based recommendation makes sense here, because we can recommend similar movies, but not other categories that a user might like because we can not identify similar users with an incomplete user profile.\n",
    "\n",
    "3) Case >=20 rated movies:  Collaborative recommender system\n",
    "\n",
    " - Collaborative filtering makes sense if you have a good user profile, which we assume we have if a user rated more or equal than 10 movies. With a good user profile we can identify similar users and make more sophisticated recommendations, e.g. movies from other genres.\n",
    "\n",
    "#### Dataset\n",
    "We use the movie recommendation lab dataset, which is a subset of the MovieLens dataset (https://grouplens.org/datasets/movielens/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature\n",
    "\n",
    "- https://users.ece.cmu.edu/~dbatra/publications/assets/goel_batra_netflix.pdf\n",
    "- http://delivery.acm.org/10.1145/1460000/1454012/p11-park.pdf?ip=72.19.68.210&id=1454012&acc=ACTIVE%20SERVICE&key=73B3886B1AEFC4BB%2EB478147E31829731%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1543416754_7f92e0642e26e7ea732886879096c704\n",
    "- https://www.kaggle.com/prajitdatta/movielens-100k-dataset/kernels\n",
    "- https://medium.com/@james_aka_yale/the-4-recommendation-engines-that-can-predict-your-movie-tastes-bbec857b8223\n",
    "- https://www.kaggle.com/c/predict-movie-ratings\n",
    "- https://cseweb.ucsd.edu/classes/wi17/cse258-a/reports/a048.pdf\n",
    "- https://github.com/neilsummers/predict_movie_ratings/blob/master/movieratings.py\n",
    "- https://medium.com/@connectwithghosh/recommender-system-on-the-movielens-using-an-autoencoder-using-tensorflow-in-python-f13d3e8d600d\n",
    "### A few more\n",
    "- https://sci2s.ugr.es/keel/pdf/specific/congreso/xia_dong_06.pdf (Uses SMV for classification, then MF for recommendation)\n",
    "- https://www.kaggle.com/rounakbanik/movie-recommender-systems (Employs at least three Modules for recommendation)\n",
    "- http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.703.4954&rep=rep1&type=pdf (Close to what we need, but a little too involving)\n",
    "- https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0165868 (Uses SVM and correlation matrices...I have already tried the correlation approach, looks quite good, but how to quantify accuracy?)\n",
    "- https://www.quora.com/How-do-we-use-SVMs-in-a-collaborative-recommendation (A good thread on SVM)\n",
    "-http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/ (A good tutorial on matrix factorizasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Classifier without specific user-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Content-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Collaborative recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Recommender: CodebustersRecommender\n",
    "Fits all three recommendation methods in fit method. When predicting, predict method assesses quality of user profile and predicts with respective method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Fill template with our logic \n",
    "\n",
    "class TemplateClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" An example classifier which implements a 1-NN algorithm.\n",
    "    For more information regarding how to build your own classifier, read more\n",
    "    in the :ref:`User Guide <user_guide>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_ : ndarray, shape (n_samples, n_features)\n",
    "        The input passed during :meth:`fit`.\n",
    "    y_ : ndarray, shape (n_samples,)\n",
    "        The labels passed during :meth:`fit`.\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        The classes seen at :meth:`fit`.\n",
    "    \"\"\"\n",
    "    def __init__(self, demo_param='demo'):\n",
    "        self.demo_param = demo_param\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"A reference implementation of a fitting function for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The training input samples.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The target values. An array of int.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" A reference implementation of a prediction for a classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            The label for each sample is the label of the closest sample\n",
    "            seen udring fit.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        closest = np.argmin(euclidean_distances(X, self.X_), axis=1)\n",
    "        return self.y_[closest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation to test and anticipate overfitting problem\n",
    "def crossvalidate(clf, X,y):\n",
    "    '''\n",
    "    Calculate precision, recall, and roc_auc for a 10-fold cross validation run with passed classifier\n",
    "    '''\n",
    "    scores1 = cross_val_score(clf, X, y, cv=10, scoring='precision')\n",
    "    scores2 = cross_val_score(clf, X, y, cv=10, scoring='recall')\n",
    "    scores3 = cross_val_score(clf, X, y, cv=10, scoring='roc_auc')\n",
    "    # The mean score and standard deviation of the score estimate\n",
    "    print(\"Cross Validation Precision: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std()))\n",
    "    print(\"Cross Validation Recall: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std()))\n",
    "    print(\"Cross Validation roc_auc: %0.2f (+/- %0.2f)\" % (scores3.mean(), scores3.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "# from http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "def get_crossval_roc(clfname, classifier,X,y):\n",
    "    '''\n",
    "    Run classifier with cross-validation and plot ROC curves\n",
    "    '''\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=6)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, y):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Chance', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lessons learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
